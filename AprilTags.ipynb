{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8eb931f-94fd-44bb-8c3b-8efec147e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "from pyapriltags import Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe40e4a-965e-4824-994a-7c415661a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_detector = Detector(families='tag16h5',\n",
    "                        nthreads=1,\n",
    "                        quad_decimate=1.0,\n",
    "                        quad_sigma=0.0,\n",
    "                        refine_edges=1,\n",
    "                        decode_sharpening=0.25,\n",
    "                        debug=0)\n",
    "fx = 460.92495728   # FOV(x) -> depth2xyz -> focal length (x)\n",
    "fy = 460.85058594   # FOV(y) -> depth2xyz -> focal length (y)\n",
    "cx = 315.10949707   # 640 (width) 320\n",
    "cy = 176.72598267   # 360 (height) 180\n",
    "#cam_intrinsic_params = open3d.camera.PinholeCameraIntrinsic(640, 360, fx, fy, cx, cy)\n",
    "camera_params = ( fx, fy, cx, cy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20aaefc6-820d-4002-afef-925891593489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "img = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6333410-abf8-45a8-8391-05093bb508ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "check, frame = cam.read()\n",
    "img = frame\n",
    "cv2.imshow('video', frame)\n",
    "key = cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d9e021-df0b-452c-bc5a-ee9ae7aa9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.fromarray(img)\n",
    "im.save(\"april_tag.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87118091-823c-4212-a82e-e6924547a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = at_detector.detect(\n",
    "  cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), True, camera_params, 2.5)\n",
    "found_tag = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b442df76-9604-417e-a4fb-619e48c5d100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[[ 0.35081022 -0.91634407  0.19299157]\n",
      " [ 0.30457483  0.30653413  0.90181539]\n",
      " [-0.88553168 -0.25758568  0.38663064]] [[139.66267904]\n",
      " [-16.3585617 ]\n",
      " [ 46.60060671]]\n"
     ]
    }
   ],
   "source": [
    "tag = tags[0]\n",
    "print(tag.tag_id)\n",
    "print(tag.pose_R, tag.pose_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc8e5355-eef3-4810-9953-599d86cc43b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation:  [-51.45512762  47.86570661  54.18533697]\n",
      "Rotation:  [ 69.05131589  11.12742028 -66.79398496]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "print(\"Rotation: \", R.from_matrix(tag.pose_R).as_rotvec(degrees=True))\n",
    "print(\"Rotation: \", R.from_matrix(tag.pose_R).as_euler(\"zyx\", degrees=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7efb93c-6219-4f52-87ae-742ff5a33ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_axis_rotation = # get first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a49d34b-c5ed-43f2-ad37-d5588f98ebb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-40.09440847],\n",
       "       [112.38181413],\n",
       "       [ 65.72196442]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.pose_t #xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c82abc1a-6b5b-45c6-8e32-4d082b3863fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing in a\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pyapriltags import Detector\n",
    "from scipy.spatial.transform import Rotation\n",
    "​\n",
    "#######################################################################################\n",
    "## Camera Config\n",
    "#######################################################################################\n",
    "​\n",
    "T_robot_camera = np.array([\n",
    "  [ 0.000, -0.342,  0.940, -14],\n",
    "  [-1.000,  0.000,  0.000,   0],\n",
    "  [ 0.000, -0.940, -0.342,  11],\n",
    "  [ 0.000,  0.000,  0.000,   1]\n",
    "], np.float32) # camera in reference frame of robot, you will need to calibrate this\n",
    "T_camera_robot = np.linalg.inv(T_robot_camera)\n",
    "​\n",
    "fx = 460.92495728\n",
    "fy = 460.85058594\n",
    "cx = 315.10949707\n",
    "cy = 176.72598267\n",
    "camera_params = ( fx, fy, cx, cy )\n",
    "​\n",
    "#######################################################################################\n",
    "## Tag Config\n",
    "#######################################################################################\n",
    "​\n",
    "tag_size = 3.0 # on a 4in apriltag, only the interior black square is measured\n",
    "​\n",
    "tag_poses = {\n",
    "  1: np.array([\n",
    "    [0, 0, -1, -72],\n",
    "    [1, 0, 0, 24],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "  ], np.float32),\n",
    "  2: np.array([\n",
    "    [1, 0, 0, -24],\n",
    "    [0, 0, 1, 72],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "  ], np.float32),\n",
    "  3: np.array([\n",
    "    [1, 0, 0, 24],\n",
    "    [0, 0, 1, 72],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "  ], np.float32),\n",
    "  4: np.array([\n",
    "    [0, 0, 1, 72],\n",
    "    [-1, 0, 0, 24],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "  ], np.float32),\n",
    "  5: np.array([\n",
    "    [0, 0, 1, 72],\n",
    "    [-1, 0, 0, -24],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "  ], np.float32),\n",
    "  6: np.array([\n",
    "    [-1, 0, 0, 24],\n",
    "    [0, 0, -1, -72],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "  ], np.float32),\n",
    "  7: np.array([\n",
    "    [-1, 0, 0, -24],\n",
    "    [0, 0, -1, -72],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "  ], np.float32),\n",
    "  8: np.array([\n",
    "    [0, 0, -1, -72],\n",
    "    [1, 0, 0, -24],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "  ], np.float32),\n",
    "}\n",
    "​\n",
    "​\n",
    "#######################################################################################\n",
    "## Apriltag Localization!!!\n",
    "#######################################################################################\n",
    "​\n",
    "detector = Detector(\n",
    "  families='tag16h5',\n",
    "  nthreads=1,\n",
    "  quad_decimate=1.0,\n",
    "  quad_sigma=0.0,\n",
    "  refine_edges=1,\n",
    "  decode_sharpening=0.25,\n",
    "  debug=0)\n",
    "​\n",
    "def detect(color_image):\n",
    "  tags = detector.detect(\n",
    "        img=cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY),\n",
    "        estimate_tag_pose=True,\n",
    "        camera_params=camera_params,\n",
    "        tag_size=tag_size)\n",
    "      \n",
    "  tags = [tag for tag in tags if tag.decision_margin > 50 and tag.tag_id in tag_poses.keys()]\n",
    "  return tags\n",
    "​\n",
    "def Rt2T(R, t):\n",
    "  T = np.eye(4, dtype=np.float32)\n",
    "  T[:3, :3] = R\n",
    "  T[:3, 3:] = t\n",
    "  return T\n",
    "​\n",
    "def localize(tags):\n",
    "  # use the formula present in the video, just with the first tag\n",
    "  if len(tags) == 0: return None\n",
    "  tag = tags[0]\n",
    "  T_camera_apriltag = Rt2T(tag.pose_R, tag.pose_t)\n",
    "  T_map_apriltag = tag_poses[tag.tag_id]\n",
    "  T_apriltag_camera = np.linalg.inv(T_camera_apriltag)\n",
    "  T_map_robot = T_map_apriltag @ T_apriltag_camera @ T_camera_robot\n",
    "  return T_map_robot\n",
    "​\n",
    "if __name__ == \"__main__\":\n",
    "  # robot = RemoteInterface(...)\n",
    "  # camera = RealsenseCamera()\n",
    "  camera = cv2.VideoCapture(0)\n",
    "​\n",
    "  while True:\n",
    "    # color, depth, sensors = robot.read()\n",
    "    # color, depth = camera.read()\n",
    "    _, color = camera.read()\n",
    "    if color is not None:\n",
    "      tags = detect(color)\n",
    "      T = localize(tags)\n",
    "      if T is not None: # we found a position!\n",
    "        x, y = T[0, 3], T[1, 3]\n",
    "        yaw = Rotation.from_matrix(T[:3, :3]).as_euler(\"zyx\", degrees=True)[0]\n",
    "        print(x, y, yaw)\n",
    "      else:\n",
    "        print(\"no tags found, so we can't localize\")\n",
    "Collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24514ab5-a161-42e8-823f-4a19cffac345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
